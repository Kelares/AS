Great name! Here's the updated `README.md` incorporating the full project name **W\.A.S.T.E.** (Waste Assessment and Sorting Technology Engine):

---

# â™»ï¸ W\.A.S.T.E.

**Waste Assessment and Sorting Technology Engine**

W\.A.S.T.E. is an intelligent, camera-powered trash can that identifies and sorts waste materials using real-time image classification and servo-controlled bins. Built with a Raspberry Pi 5 and a fine-tuned YOLO model, this system brings smart automation to everyday recycling.

---

## ğŸš€ Features

* ğŸ“¸ **AI Classification** using a fine-tuned YOLOv8 model (ONNX)
* ğŸ¤– **Automatic sorting** via two servo-controlled lids
* ğŸ‘‹ **Hands-free activation** with ultrasonic proximity detection
* ğŸ’¡ **LED indicators** for status and feedback
* ğŸ§  **Majority-vote logic** for increased classification confidence

---

## ğŸ§° Hardware Components

| Component          | Description                        |
| ------------------ | ---------------------------------- |
| Raspberry Pi 5     | Central controller                 |
| Ultrasonic Sensor  | Detects nearby objects             |
| Camera Module      | Captures images for classification |
| Servo x2           | Controls left and right bin lids   |
| LED x2             | Yellow (status), Red (error)       |
| Breadboard + Wires | Electrical connections             |

---

## ğŸ–¼ï¸ Waste Categories

| Category             | Sorted To          |
| -------------------- | ------------------ |
| Paper                | Left               |
| Cardboard            | Left               |
| Plastic              | Right              |
| Metal                | Right              |
| Background / Unknown | Rejected (red LED) |

---

## ğŸ› ï¸ Setup

### ğŸ§¾ Prerequisites

Install the necessary Python packages:

```bash
pip install ultralytics numpy pillow gpiozero picamera2
```

Ensure:

* `model.onnx` is in the same directory.
* Camera is enabled via `libcamera`.

### ğŸ§¬ GPIO Pin Assignments

| Component            | GPIO Pin |
| -------------------- | -------- |
| Trigger (Ultrasonic) | 4        |
| Echo (Ultrasonic)    | 17       |
| Left Servo           | 12       |
| Right Servo          | 18       |
| Yellow LED           | 15       |
| Red LED              | 26       |

---

## ğŸ§  How It Works

1. **Detect proximity** with the ultrasonic sensor.
2. **Capture 50 frames** via camera.
3. **Classify each frame** with the YOLO model.
4. **Determine most frequent confident label**.
5. **Activate appropriate servo** (left or right).
6. **Blink red LED** if classification is inconclusive.

---

## ğŸ§ª Example Run

```text
ğŸ” Object detected near the sensor
ğŸ“· Capturing frames...
âœ… Detected: plastic (confidence: 0.92)
ğŸ› Activating Right Servo
ğŸ”„ Waiting for next object...
```

If the model cannot confidently identify the object, the red LED blinks and no sorting occurs.

---

## ğŸ§  Logic Highlights

* **Confidence threshold:** 0.6
* **Background class** is ignored
* **Majority voting** (min 4 positive detections) used for robustness
* **Parallel LED blinking** using `multiprocessing`

---

## ğŸ“¸ Demo & Images

*Coming soon â€” feel free to contribute with setup pictures or video demos!*

---

## ğŸ“œ License

Open-source for educational and non-commercial use.

---

## ğŸ™Œ Credits

* [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)
* Raspberry Pi Foundation
* Project by: **\[Your Name]**

---

Let me know if youâ€™d like to add wiring diagrams, schematics, or a video tutorial section.
